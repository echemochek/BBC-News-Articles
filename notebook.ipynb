{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Tagging: BBC News Articles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corpus used in this project includes 2,225 documents from BBC's news website corresponding to stories in five topical areas (business, entertainment, politics, sport, tech) from 2004-2005. \n",
    "\n",
    "The CSV file includes two columns: category (the five class labels) and text (pre-processed article content). In this project, I will use only the text column.\n",
    "\n",
    "More information on this data set as well as a paper written using this data set is available here http://mlg.ucd.ie/datasets/bbc.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  tv future in the hands of viewers with home th...\n",
       "1  worldcom boss  left books alone  former worldc...\n",
       "2  tigers wary of farrell  gamble  leicester say ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/BBC-articles.csv\")\n",
    "df = df[['text']][:100]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data (options: TF-IDF, ...)\n",
    "def vectorizeStep(inputData, fittingData=df.text, outputFormat=\"tfidf\"):\n",
    "    \n",
    "    # TF-IDF input\n",
    "    if outputFormat == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, \n",
    "                            analyzer='word', stop_words='english'\n",
    "                            )\n",
    "\n",
    "        vectorizer.fit(fittingData)\n",
    "        \n",
    "        transformedData = vectorizer.transform(inputData)\n",
    "    \n",
    "    return transformedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes as input a df and name of column (containing sentences) in the df.\n",
    "The input is split to tokens which are lemmatized, and stopwords removed.\n",
    "The output is a list of lists.  \n",
    "'''\n",
    "def preprocess_text(text):\n",
    "    cleanText=[]\n",
    "    lem = WordNetLemmatizer()\n",
    "    stop = set(stopwords.words('english'))\n",
    "\n",
    "    for txt in text:\n",
    "        words = [w for w in word_tokenize(txt) if (w not in stop)]\n",
    "        words = [lem.lemmatize(w) for w in words if len(w)>2]\n",
    "        cleanText.append(words)        \n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedText = preprocess_text(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "txt = df['text'].str.split()\n",
    "txt = txt.values.tolist()\n",
    "txt[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW model\n",
    "dic_bow = gensim.corpora.Dictionary(preprocessedText)\n",
    "bow_corpus = [dic_bow.doc2bow(doc) for doc in preprocessedText]\n",
    "\n",
    "# tfidf model\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "# LDA using BoW\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dic_bow, passes=2, workers=2)\n",
    "\n",
    "# LDA using TF-IDF\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=5, id2word=dic_bow, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic No: 2\t\n",
      "Score: 0.9973008036613464\t\n",
      "Topic Model: 0.012*\"said\" + 0.006*\"year\" + 0.005*\"government\" + 0.005*\"would\" + 0.004*\"price\" + 0.004*\"music\" + 0.004*\"last\" + 0.004*\"new\" + 0.003*\"market\" + 0.003*\"people\"\n"
     ]
    }
   ],
   "source": [
    "# testing on a select output using LDA BoW model\n",
    "x = 88\n",
    "\n",
    "for index, score in sorted(lda_model[bow_corpus[x]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nTopic No: {}\\t\\nScore: {}\\t\\nTopic Model: {}\".format(index, score, lda_model.print_topic(index, 10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic No: 3\t\n",
      "Score: 0.9741422533988953\t\n",
      "Topic Model: 0.001*\"music\" + 0.001*\"rate\" + 0.001*\"fox\" + 0.001*\"pop\" + 0.001*\"government\" + 0.001*\"bank\" + 0.001*\"party\" + 0.001*\"election\" + 0.001*\"ice\" + 0.001*\"pension\"\n",
      "\n",
      "Topic No: 2\t\n",
      "Score: 0.023825105279684067\t\n",
      "Topic Model: 0.001*\"fiat\" + 0.001*\"child\" + 0.001*\"film\" + 0.001*\"club\" + 0.001*\"hendrix\" + 0.001*\"coach\" + 0.001*\"rugby\" + 0.001*\"human\" + 0.001*\"project\" + 0.001*\"ufj\"\n"
     ]
    }
   ],
   "source": [
    "# testing on a select output using LDA TF-IDF model\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[x]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nTopic No: {}\\t\\nScore: {}\\t\\nTopic Model: {}\".format(index, score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.99730057)] \n",
      " [(2, 0.023875587), (3, 0.9740918)]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model[bow_corpus[x]], \"\\n\",lda_model_tfidf[bow_corpus[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# print the 5 topics\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5, \n",
    "                                   id2word = dic_bow,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top keywords in each topic\n",
    "topic= []\n",
    "keywords = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    for index, score in sorted(lda_model[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        topic.append(index)\n",
    "\n",
    "        elements = lda_model.print_topic(index, 5).split(\"+\")\n",
    "        keywords.append([x.strip().replace('\"', '').split(\"*\")[1] for x in elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bow_corpus), len(topic), len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(lda_model[bow_corpus[1]], key=lambda tup: -1*tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topicID, value in topics[:1]:\n",
    "    elements = value.split(\"+\")[:5]\n",
    "    for element in elements:\n",
    "        word = element.split(\"*\")[1]\n",
    "        print(word)\n",
    "\n",
    "\n",
    "        # print(f\"The topic would be: {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interacting with LDA output\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = gensimvis.prepare(lda_model, bow_corpus, dic_bow)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Keywords to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfe9ce709e982859ebd8c1b094ee35d9f73a27801040ad55cc46450c9d5cadda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
