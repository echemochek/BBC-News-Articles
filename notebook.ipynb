{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Tagging: BBC News Articles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corpus used in this project includes 2,225 documents from BBC's news website corresponding to stories in five topical areas (business, entertainment, politics, sport, tech) from 2004-2005. \n",
    "\n",
    "The CSV file includes two columns: category (the five class labels) and text (pre-processed article content). In this project, I will use only the text column.\n",
    "\n",
    "More information on this data set as well as a paper written using this data set is available here http://mlg.ucd.ie/datasets/bbc.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  tv future in the hands of viewers with home th...\n",
       "1  worldcom boss  left books alone  former worldc...\n",
       "2  tigers wary of farrell  gamble  leicester say ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/BBC-articles.csv\")\n",
    "df = df[['text']][:100]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes as input a df and name of column (containing sentences) in the df.\n",
    "The input is split to tokens which are lemmatized, and stopwords removed.\n",
    "The output is a list of lists.  \n",
    "'''\n",
    "import re\n",
    "def preprocess_text(text):    \n",
    "    cleanTokens=[]\n",
    "    #cleanText= \"\"\n",
    "    lem = WordNetLemmatizer()\n",
    "    stop = set(stopwords.words('english'))\n",
    "\n",
    "    for txt in text:\n",
    "        words = [lem.lemmatize(w) for w in word_tokenize(txt) if (w not in stop) and len(w)>2]\n",
    "        cleanTokens.append(words)        \n",
    "\n",
    "    return cleanTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleanTokens</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>[future, hand, viewer, home, theatre, system, ...</td>\n",
       "      <td>[future, hand, viewer, home, theatre, system, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>[worldcom, bos, left, book, alone, former, wor...</td>\n",
       "      <td>[worldcom, bos, left, book, alone, former, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
       "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>[yeading, face, newcastle, cup, premiership, s...</td>\n",
       "      <td>[yeading, face, newcastle, cup, premiership, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>[ocean, twelve, raid, box, office, ocean, twel...</td>\n",
       "      <td>[ocean, twelve, raid, box, office, ocean, twel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  tv future in the hands of viewers with home th...   \n",
       "1  worldcom boss  left books alone  former worldc...   \n",
       "2  tigers wary of farrell  gamble  leicester say ...   \n",
       "3  yeading face newcastle in fa cup premiership s...   \n",
       "4  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "                                         cleanTokens  \\\n",
       "0  [future, hand, viewer, home, theatre, system, ...   \n",
       "1  [worldcom, bos, left, book, alone, former, wor...   \n",
       "2  [tiger, wary, farrell, gamble, leicester, say,...   \n",
       "3  [yeading, face, newcastle, cup, premiership, s...   \n",
       "4  [ocean, twelve, raid, box, office, ocean, twel...   \n",
       "\n",
       "                                           cleanText  \n",
       "0  [future, hand, viewer, home, theatre, system, ...  \n",
       "1  [worldcom, bos, left, book, alone, former, wor...  \n",
       "2  [tiger, wary, farrell, gamble, leicester, say,...  \n",
       "3  [yeading, face, newcastle, cup, premiership, s...  \n",
       "4  [ocean, twelve, raid, box, office, ocean, twel...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleanText'] = preprocess_text(df.text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data (options: TF-IDF, TF-IDF ngrams, word2vec, doc2vec)\n",
    "def vectorizeStep(inputData, fittingData=df.text, outputFormat=\"tfidfUnfiltered\"):\n",
    "    \n",
    "    # TF-IDF input\n",
    "    if outputFormat == \"tfidf\":\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, analyzer='word', \n",
    "                            stop_words='english', max_df=0.9, min_df=5\n",
    "                                )\n",
    "        vectorizer.fit(fittingData)\n",
    "        \n",
    "        transformedData = vectorizer.transform(inputData)\n",
    "    \n",
    "    # TF-IDF ngrams input\n",
    "    elif outputFormat == \"tfidfFiltered\":\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        vectorizer = TfidfVectorizer(\n",
    "                            strip_accents=\"unicode\", lowercase=True, analyzer='word', ngram_range=(2,3), \n",
    "                            max_df=0.9, min_df=5\n",
    "                            )\n",
    "        vectorizer.fit(fittingData)\n",
    "        \n",
    "        transformedData = vectorizer.transform(inputData)\n",
    "        \n",
    "    return transformedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecCorpus = vectorizeStep(df.text, fittingData=df.text, outputFormat=\"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW model\n",
    "dic_bow = gensim.corpora.Dictionary(df.cleanText)\n",
    "bow_corpus = [dic_bow.doc2bow(doc) for doc in df.cleanText]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf model\n",
    "from gensim import corpora, models\n",
    "tfidfGensim = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidfGensim[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA using TF-IDF\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "\n",
    "lda_model_tfidf = LdaMulticore(corpus_tfidf, num_topics=5, id2word=dic_bow, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic No: 2\t\n",
      "Score: 0.9886234402656555\t\n",
      "Topic Model: 0.001*\"phone\" + 0.001*\"government\" + 0.001*\"mobile\" + 0.001*\"music\" + 0.001*\"yukos\"\n"
     ]
    }
   ],
   "source": [
    "# testing on a select output using LDA TF-IDF model\n",
    "x = 51\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[x]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nTopic No: {}\\t\\nScore: {}\\t\\nTopic Model: {}\".format(index, score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top keywords in each topic\n",
    "keywords = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    for index, score in sorted(lda_model_tfidf[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        elements = lda_model_tfidf.print_topic(index, 5).split(\"+\")\n",
    "        keywords.append([x.strip().replace('\"', '').split(\"*\")[1] for x in elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.9953849)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lda_model_tfidf[bow_corpus[1]], key=lambda tup: -1*tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echemochek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "C:\\Users\\echemochek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el990828773112255206394267984\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el990828773112255206394267984_data = {\"mdsDat\": {\"x\": [0.008919002303205055, -0.003883622880630589, -0.002370176266296016, -0.0014647720312241316, -0.0012004311250543179], \"y\": [0.00045504813088503095, 0.004725053033334699, -0.007193328099644728, 0.0012898742093981634, 0.0007233527260268345], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.99624846986588, 24.48537500346181, 24.40380807786721, 14.779817002548116, 9.334751446256979]}, \"tinfo\": {\"Term\": [\"hague\", \"party\", \"fiat\", \"fox\", \"sayeed\", \"farrell\", \"rugby\", \"robinson\", \"west\", \"dicaprio\", \"osbournes\", \"henman\", \"ferguson\", \"blue\", \"virgin\", \"league\", \"ranieri\", \"ranger\", \"cup\", \"wilkinson\", \"marsh\", \"match\", \"break\", \"winter\", \"donation\", \"valencia\", \"australia\", \"singapore\", \"human\", \"pensioner\", \"hendrix\", \"ball\", \"ukraine\", \"panda\", \"solskjaer\", \"pernod\", \"child\", \"lewsey\", \"cell\", \"broadband\", \"ntpc\", \"fbi\", \"e-mail\", \"federer\", \"coach\", \"nintendo\", \"rate\", \"console\", \"bonus\", \"gorge\", \"dam\", \"referee\", \"immunisation\", \"khodorkovsky\", \"connors\", \"aynsley-green\", \"yushchenko\", \"lebedev\", \"ireland\", \"stock\", \"good\", \"power\", \"network\", \"million\", \"firm\", \"england\", \"player\", \"share\", \"price\", \"mobile\", \"ufj\", \"hingis\", \"phone\", \"worldcom\", \"vioxx\", \"sumitomo\", \"villa\", \"titan\", \"benin\", \"roddick\", \"sequel\", \"ebbers\", \"bowles\", \"parker\", \"cole\", \"hill\", \"carpenter\", \"halloween\", \"ocean\", \"drug\", \"yukos\", \"audio\", \"indonesia\", \"merck\", \"prince\", \"ankle\", \"kerekou\", \"davis\", \"sound\", \"pension\", \"donation\", \"government\", \"music\", \"japan\", \"party\", \"company\", \"face\", \"argonaut\", \"student\", \"tobacco\", \"firefox\", \"ice\", \"jamieson\", \"kasabian\", \"blog\", \"bates\", \"pop\", \"microsoft\", \"award\", \"celebrity\", \"journalist\", \"browser\", \"hutt\", \"gibbon\", \"rochus\", \"johansson\", \"dent\", \"waiting\", \"submission\", \"msn\", \"tuc\", \"rugby\", \"web\", \"page\", \"goldsmith\", \"atp\", \"bbc\", \"audience\", \"wale\", \"price\", \"top\", \"howard\", \"club\", \"film\", \"lord\", \"crude\", \"people\", \"000\", \"music\", \"hague\", \"fiat\", \"fox\", \"sayeed\", \"dicaprio\", \"blue\", \"virgin\", \"singapore\", \"scholl\", \"tps\", \"front\", \"straw\", \"break\", \"human\", \"bus\", \"german\", \"truant\", \"pupil\", \"intention\", \"marketing\", \"ambition\", \"amnesty\", \"bench\", \"leadership\", \"khan\", \"voting\", \"aviator\", \"fourth\", \"party\", \"stand\", \"conservative\", \"film\", \"quarter\", \"growth\", \"right\", \"economy\", \"corp\", \"share\", \"school\", \"farrell\", \"osbournes\", \"ferguson\", \"ranieri\", \"marsh\", \"wilkinson\", \"robinson\", \"henman\", \"ranger\", \"valencia\", \"west\", \"spitzer\", \"insurance\", \"osbourne\", \"ozzy\", \"gamble\", \"insulation\", \"australia\", \"pensioner\", \"artist\", \"hopman\", \"slovakia\", \"hip-hop\", \"league\", \"autumn\", \"6-4\", \"25-year-old\", \"code\", \"guilty\", \"mtv\", \"cup\", \"match\", \"rugby\", \"winter\", \"party\", \"donation\", \"captain\", \"england\"], \"Freq\": [6.0, 7.0, 4.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 5.0, 3.0, 3.201991535952819, 3.332061968654569, 3.170610700632505, 3.102310407703198, 3.06612457891923, 3.0446260114496075, 3.854877135783518, 2.7900852609927638, 2.6699757210825013, 3.018493161477283, 2.5842004996772032, 2.483080565604358, 2.482945342943532, 2.6204013192086384, 2.974852954065059, 2.4323734444958602, 3.6013817605122913, 2.4654667432640793, 2.476111091766621, 2.2841268834570023, 2.283620257379337, 2.2831085833969125, 2.25825071179335, 2.5469703664752945, 2.2057879905962756, 2.1740307039543634, 2.1729354615883962, 2.16432694837198, 2.8329762369652522, 2.675810487117062, 2.5477067487029155, 2.687774633263956, 2.564467934039297, 2.531007514924944, 2.7852717013876997, 2.5498256449673535, 2.495017942559347, 2.508591146589985, 2.4841221166197034, 3.075982352504484, 2.7381649315737726, 2.6827420536062503, 3.250255986013958, 2.368058912277146, 2.2967869730753563, 2.292043048648877, 2.2784881860610064, 2.223000377943115, 2.2226307755487027, 2.1889364671752105, 2.2319067689751346, 2.183829183638008, 2.1219071860894605, 2.1214440731793447, 2.119362701136937, 2.242471514894696, 2.0649133592060487, 2.064861193102333, 2.05429991567371, 2.210144208169907, 2.7728198731976064, 1.9780821858728168, 2.01655760089565, 1.9485914110375775, 2.0607893234801073, 1.9312679636751493, 1.923827218174125, 1.9076881910973942, 2.04497355975885, 2.691184915509242, 2.4016358469172774, 3.141130046625887, 2.781787448409782, 2.3455520133165044, 2.2608756052939403, 2.151880636123709, 2.0717070230375763, 3.0891082464455426, 2.858930202072624, 2.817075273954236, 2.6597492630246165, 2.7778780386364725, 2.525450044567254, 2.588282769740644, 2.217235668182826, 2.379240711838124, 2.6839688368755517, 2.3057072470669646, 2.617670325419391, 2.0645337938268633, 2.09495566491397, 2.062313057803032, 2.0362779008890275, 2.0361313267803562, 1.9668739542134899, 1.966848787715586, 1.9668190580614686, 2.1189686522381552, 1.9182685970034845, 1.91783288472384, 1.917872846910072, 2.673506487620565, 1.8633507354208825, 1.849165265528184, 1.8324034099819355, 1.8062352301504383, 2.613601925961536, 1.9044907690658455, 2.548388339464465, 2.9190253100729255, 2.2490367186660527, 2.375004996652446, 2.5629943111160967, 2.761986363152364, 2.1908051760077916, 2.1670131560663015, 2.3590488838715062, 2.161910441200087, 2.0795624796768046, 3.666973119487185, 2.1741063785142183, 2.0960097681086047, 2.049269749400254, 1.896235251342355, 1.8235462724555882, 1.8233704063496976, 1.56712712538875, 1.5183207636819476, 1.4313682061497937, 1.4233900821289418, 1.3150823545957677, 1.6640452614298507, 1.8198524142657648, 1.1442935869278437, 1.2746762793097197, 1.1630116027981496, 1.1614008367597197, 1.1078560559398676, 1.1941486131003431, 1.2864736289301655, 1.0426083907221624, 1.0998026444765416, 1.0997362340851269, 1.0538900339235249, 0.999874350668709, 0.9987489750825376, 1.1935834129343161, 2.1268156476571356, 1.1503358438516618, 1.2437596878602426, 2.122791831154355, 1.4817047704693749, 1.5005221088166267, 1.4530667337861243, 1.452925370935294, 1.1929423391054619, 1.4091305232802607, 1.2133540293212606, 1.0572091122535665, 0.9946095319043772, 0.9776086224843286, 0.9545400626699998, 0.9200393589444562, 0.9414232830928114, 1.0603383560611122, 1.0196891817435614, 0.9720803728599573, 0.8563655787290108, 1.0234007752742582, 0.7644406964127869, 0.7643907656100026, 0.762725488708668, 0.7626866653937912, 0.7535111398829876, 0.7519692618830254, 0.8412389256613568, 0.8125515108570113, 0.7561071713781727, 0.711087041890615, 0.7110768335803, 0.7060612738620601, 1.0117949314092898, 0.7220559506632868, 0.7484869586384194, 0.6767037072872942, 0.6935101298833622, 0.7817616601629708, 0.6464526226495679, 1.0316618900662753, 1.033805317875629, 0.995182572494806, 0.8645690403695079, 0.9855495242678117, 0.8134269924753219, 0.7410256887613427, 0.810247817864992], \"Total\": [6.0, 7.0, 4.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 5.0, 3.0, 5.4167723706326605, 5.657255857199562, 5.3845681141242245, 5.316569805974542, 5.280753351494905, 5.258740926771948, 6.809824111441803, 5.015793389315869, 4.948263653184564, 5.6149744800221955, 4.864107341001474, 4.697292095587444, 4.697270078237729, 4.957570218651253, 5.666755246601553, 4.647053167522142, 6.937600422603848, 4.810475307634527, 4.844876633262578, 4.497809794347249, 4.497552850977078, 4.5026937332035555, 4.471987479141726, 5.0983055099369095, 4.419436548494441, 4.388017643213072, 4.386510746204776, 4.378259652299078, 5.737148732228002, 5.449526587658341, 5.351699216003211, 5.967370631306354, 5.68975097185731, 5.653289263678951, 6.844236210274983, 6.615710292290105, 6.417408473767139, 6.718524968395575, 7.352179968534806, 5.525948485857765, 4.9992936662937355, 4.943502848432706, 6.327574061986957, 4.687103720169257, 4.557196413400818, 4.552752551018218, 4.539153624822172, 4.483556611324242, 4.4833371836984, 4.449562385398037, 4.54045131759007, 4.487039977270635, 4.382072096874486, 4.3819150927839665, 4.380214960184108, 4.666303481684066, 4.3252314729362125, 4.3251773216862635, 4.3594299957343825, 4.6963941742421955, 5.915387558406689, 4.2382281797580434, 4.3387768358692185, 4.208773451832079, 4.453874786118668, 4.1919399480520285, 4.184428410391089, 4.177690422400358, 4.494992923403954, 5.953996091154026, 5.426252551328132, 7.618783155172129, 6.787955890728394, 6.118991564456165, 7.560339243281825, 6.766288783749178, 4.971685362471909, 5.359378407190269, 5.129219273942835, 5.087124493962714, 4.9295873546350375, 5.258075147424081, 4.795307265030091, 4.932698347225207, 4.486976198264599, 4.866124092496694, 5.5351513741055065, 4.804727255438996, 5.469078072446746, 4.334268997548777, 4.398929028546427, 4.332228621028054, 4.305866320532604, 4.305760992214646, 4.236725920116566, 4.236717034820769, 4.236768812994515, 4.592628052206702, 4.188043007799646, 4.18738142266581, 4.187912887995438, 5.906359834050795, 4.132919934154986, 4.1311781578063265, 4.101788104832493, 4.075696227936502, 5.936978259057818, 4.333106184093247, 6.11269715331482, 7.352179968534806, 5.417109947834703, 5.923208634630609, 6.753962781780151, 8.873142063868757, 5.539703392898253, 5.680933888237848, 7.699870397280295, 6.068300606797727, 6.787955890728394, 6.200066455811565, 4.705856777431629, 4.627559922678179, 4.580634385191267, 4.427151128763524, 4.355178184392314, 4.3552340024332, 4.097532624316219, 4.048581176975403, 3.9613865016277163, 4.138827998561955, 3.845051123425329, 4.926823790373335, 5.581252046336476, 3.67399509349535, 4.1431662618651774, 3.797092735051928, 3.7980224570427357, 3.6375164529951105, 3.976076887897376, 4.320411077290629, 3.5721764568392222, 3.773296987446683, 3.793329317655339, 3.640881236199711, 3.529539789418448, 3.5287021241842806, 4.222482509542085, 7.560339243281825, 4.106465219000515, 4.447149732582024, 8.873142063868757, 5.716905616187848, 6.020585351643067, 5.820889133248263, 5.8311377920712175, 4.418423965772259, 6.718524968395575, 4.6885102721618965, 3.750686845987669, 3.68808201050618, 3.6708830462926145, 3.648077709037463, 3.6133038789194254, 3.8267961280601566, 4.3186016221824355, 4.176938176810711, 4.2380079881912645, 3.753547762867627, 4.60181627168761, 3.457580905370528, 3.45759760716569, 3.4552241118075355, 3.455237705267922, 3.4464965511602017, 3.44471622216915, 3.944321571297875, 3.8424199534686276, 3.613752712236855, 3.4037138474613067, 3.403746123245506, 3.398643983856474, 4.965048136406034, 3.578274307191815, 3.7144664123276967, 3.369193671760044, 3.4978096963949654, 4.015251586737083, 3.3389890799900037, 5.339800525897074, 5.824748789116801, 5.906359834050795, 4.917842733625588, 7.560339243281825, 5.426252551328132, 3.9921585665066255, 6.615710292290105], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.4033, -7.3635, -7.4132, -7.435, -7.4467, -7.4537, -7.2178, -7.541, -7.585, -7.4623, -7.6177, -7.6576, -7.6577, -7.6038, -7.4769, -7.6782, -7.2858, -7.6647, -7.6604, -7.7411, -7.7413, -7.7416, -7.7525, -7.6322, -7.776, -7.7905, -7.791, -7.795, -7.5258, -7.5829, -7.6319, -7.5784, -7.6254, -7.6385, -7.5428, -7.6311, -7.6528, -7.6474, -7.6572, -7.3459, -7.4622, -7.4826, -7.2908, -7.6074, -7.638, -7.64, -7.646, -7.6706, -7.6708, -7.6861, -7.6666, -7.6884, -7.7172, -7.7174, -7.7184, -7.6619, -7.7444, -7.7444, -7.7495, -7.6764, -7.4496, -7.7874, -7.7681, -7.8024, -7.7464, -7.8113, -7.8152, -7.8236, -7.7541, -7.4795, -7.5933, -7.3249, -7.4464, -7.617, -7.6537, -7.7031, -7.7411, -7.3383, -7.4157, -7.4304, -7.4879, -7.4445, -7.5397, -7.5152, -7.6699, -7.5994, -7.4789, -7.6308, -7.5039, -7.7412, -7.7266, -7.7423, -7.755, -7.7551, -7.7897, -7.7897, -7.7897, -7.7152, -7.8147, -7.815, -7.8149, -7.4828, -7.8438, -7.8514, -7.8605, -7.8749, -7.5054, -7.8219, -7.5307, -7.3949, -7.6556, -7.6011, -7.525, -7.4502, -7.6819, -7.6928, -7.6079, -7.6952, -7.734, -6.6653, -7.1881, -7.2246, -7.2472, -7.3248, -7.3639, -7.364, -7.5154, -7.5471, -7.606, -7.6116, -7.6908, -7.4554, -7.3659, -7.8299, -7.722, -7.8137, -7.815, -7.8622, -7.7872, -7.7128, -7.9229, -7.8695, -7.8696, -7.9122, -7.9648, -7.9659, -7.7877, -7.21, -7.8246, -7.7465, -7.2119, -7.5715, -7.5589, -7.591, -7.5911, -7.7882, -7.6217, -7.7713, -7.4495, -7.5106, -7.5278, -7.5517, -7.5885, -7.5655, -7.4466, -7.4857, -7.5335, -7.6602, -7.482, -7.7738, -7.7738, -7.776, -7.7761, -7.7882, -7.7902, -7.678, -7.7127, -7.7847, -7.8461, -7.8461, -7.8532, -7.4934, -7.8308, -7.7949, -7.8957, -7.8711, -7.7514, -7.9414, -7.474, -7.4719, -7.51, -7.6507, -7.5197, -7.7117, -7.8049, -7.7156], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7837, 0.7801, 0.7799, 0.7708, 0.7658, 0.763, 0.7404, 0.723, 0.6925, 0.6888, 0.677, 0.672, 0.6719, 0.6719, 0.6651, 0.6621, 0.6538, 0.6411, 0.6382, 0.6319, 0.6317, 0.6303, 0.6262, 0.6155, 0.6145, 0.6072, 0.607, 0.6049, 0.6038, 0.5982, 0.5673, 0.5119, 0.5126, 0.5059, 0.4104, 0.3561, 0.3648, 0.3243, 0.2244, 0.8213, 0.8051, 0.7959, 0.7409, 0.7243, 0.7219, 0.7208, 0.7179, 0.7055, 0.7054, 0.6977, 0.6969, 0.687, 0.6819, 0.6817, 0.6811, 0.6743, 0.6677, 0.6677, 0.6547, 0.6534, 0.6494, 0.6451, 0.6409, 0.637, 0.6364, 0.6321, 0.63, 0.6232, 0.6195, 0.613, 0.592, 0.5211, 0.515, 0.4482, 0.1999, 0.2615, 0.5317, 0.8595, 0.8259, 0.8194, 0.7934, 0.7724, 0.7692, 0.7655, 0.7055, 0.6949, 0.6866, 0.6762, 0.6736, 0.6688, 0.6686, 0.6682, 0.6616, 0.6615, 0.6431, 0.6431, 0.643, 0.6369, 0.6296, 0.6296, 0.6294, 0.6178, 0.6138, 0.6066, 0.6046, 0.5966, 0.59, 0.5884, 0.5355, 0.4867, 0.5314, 0.4966, 0.4415, 0.2434, 0.4828, 0.4467, 0.2275, 0.3783, 0.2274, 1.3867, 1.1397, 1.1199, 1.1076, 1.064, 1.0413, 1.0412, 0.9508, 0.9311, 0.8939, 0.8445, 0.839, 0.8265, 0.7912, 0.7454, 0.7331, 0.7287, 0.7271, 0.723, 0.709, 0.7005, 0.6805, 0.6791, 0.6737, 0.6722, 0.6506, 0.6497, 0.6484, 0.6436, 0.6394, 0.6378, 0.4816, 0.5617, 0.5225, 0.5241, 0.5223, 0.6025, 0.35, 0.5602, 1.1051, 1.0609, 1.0483, 1.0307, 1.0035, 0.969, 0.9671, 0.9613, 0.899, 0.8937, 0.8681, 0.8622, 0.8622, 0.8607, 0.8606, 0.8511, 0.8495, 0.8263, 0.8177, 0.8071, 0.8056, 0.8056, 0.8, 0.7807, 0.7709, 0.7695, 0.7662, 0.7533, 0.7351, 0.7295, 0.7274, 0.6426, 0.5906, 0.633, 0.334, 0.4737, 0.6874, 0.2716]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.16479078160363334, 0.32958156320726667, 0.32958156320726667, 0.16479078160363334, 0.29680692100956213, 0.29680692100956213, 0.29680692100956213, 0.29680692100956213, 0.2692176719329501, 0.2692176719329501, 0.2692176719329501, 0.2692176719329501, 0.23145945654484099, 0.23145945654484099, 0.23145945654484099, 0.23145945654484099, 0.27994137805970326, 0.27994137805970326, 0.27994137805970326, 0.27994137805970326, 0.23855303568093683, 0.47710607136187366, 0.23855303568093683, 0.18658880266009514, 0.18658880266009514, 0.5597664079802854, 0.2767206501468154, 0.2767206501468154, 0.2767206501468154, 0.2767206501468154, 0.24535685293363813, 0.24535685293363813, 0.49071370586727625, 0.2307813281084552, 0.2307813281084552, 0.4615626562169104, 0.2359476549129757, 0.4718953098259514, 0.2359476549129757, 0.25352902442762826, 0.25352902442762826, 0.25352902442762826, 0.25352902442762826, 0.25352902442762826, 0.27946432110868197, 0.27946432110868197, 0.27946432110868197, 0.27946432110868197, 0.28339031315406565, 0.28339031315406565, 0.28339031315406565, 0.28339031315406565, 0.18284617384381602, 0.18284617384381602, 0.5485385215314481, 0.18284617384381602, 0.4557866815083097, 0.22789334075415485, 0.22789334075415485, 0.5302924378401812, 0.17676414594672707, 0.17676414594672707, 0.2055023630700144, 0.2055023630700144, 0.4110047261400288, 0.16843585345362158, 0.16843585345362158, 0.5053075603608648, 0.16843585345362158, 0.2650202205993546, 0.2650202205993546, 0.2650202205993546, 0.2650202205993546, 0.2230481355799072, 0.4460962711598144, 0.2230481355799072, 0.2228672397207643, 0.2228672397207643, 0.4457344794415286, 0.2296117306023684, 0.2296117306023684, 0.2296117306023684, 0.4592234612047368, 0.4128072088087792, 0.2064036044043896, 0.2064036044043896, 0.22820254388631583, 0.45640508777263167, 0.22820254388631583, 0.20297052270347665, 0.20297052270347665, 0.20297052270347665, 0.4059410454069533, 0.20297052270347665, 0.5342855983894234, 0.17809519946314112, 0.17809519946314112, 0.17809519946314112, 0.2308280766038373, 0.2308280766038373, 0.4616561532076746, 0.27218327040513934, 0.27218327040513934, 0.27218327040513934, 0.27218327040513934, 0.25049105223169005, 0.25049105223169005, 0.25049105223169005, 0.25049105223169005, 0.23120149898501116, 0.4624029979700223, 0.23120149898501116, 0.2307194132541254, 0.2307194132541254, 0.4614388265082508, 0.606273272861943, 0.202091090953981, 0.202091090953981, 0.202091090953981, 0.5873866834943999, 0.14684667087359998, 0.14684667087359998, 0.14684667087359998, 0.14806122454474477, 0.14806122454474477, 0.44418367363423433, 0.14806122454474477, 0.14806122454474477, 0.5294034892011878, 0.1764678297337293, 0.1764678297337293, 0.1764678297337293, 0.28589319797204943, 0.28589319797204943, 0.28589319797204943, 0.28589319797204943, 0.22829929788604902, 0.45659859577209805, 0.22829929788604902, 0.29558300922707686, 0.29558300922707686, 0.29558300922707686, 0.14779150461353843, 0.4525463773614614, 0.2262731886807307, 0.2262731886807307, 0.22486312810056835, 0.22486312810056835, 0.22486312810056835, 0.22486312810056835, 0.4157593318950986, 0.2078796659475493, 0.2078796659475493, 0.22632504434762143, 0.22632504434762143, 0.22632504434762143, 0.22632504434762143, 0.3520547922835226, 0.1760273961417613, 0.3520547922835226, 0.18727291312665698, 0.37454582625331395, 0.18727291312665698, 0.18727291312665698, 0.4446862696823022, 0.2223431348411511, 0.2223431348411511, 0.23936670717344205, 0.4787334143468841, 0.23936670717344205, 0.23602892773684478, 0.23602892773684478, 0.47205785547368956, 0.22587889387893878, 0.22587889387893878, 0.22587889387893878, 0.45175778775787756, 0.18428924760518925, 0.3685784952103785, 0.18428924760518925, 0.18428924760518925, 0.21292931617294641, 0.42585863234589283, 0.21292931617294641, 0.4257792221200827, 0.21288961106004134, 0.21288961106004134, 0.22286407187490168, 0.44572814374980335, 0.22286407187490168, 0.3429862355026944, 0.1714931177513472, 0.1714931177513472, 0.1714931177513472, 0.4534660478552357, 0.15115534928507857, 0.30231069857015713, 0.15115534928507857, 0.15115534928507857, 0.20113903577816167, 0.40227807155632334, 0.20113903577816167, 0.20113903577816167, 0.26661783322960136, 0.26661783322960136, 0.26661783322960136, 0.26661783322960136, 0.4257772263893842, 0.2128886131946921, 0.2128886131946921, 0.6051351504237844, 0.20171171680792815, 0.20171171680792815, 0.27241401793226394, 0.27241401793226394, 0.27241401793226394, 0.27241401793226394, 0.21250115490037966, 0.21250115490037966, 0.21250115490037966, 0.4250023098007593, 0.22539929887338972, 0.22539929887338972, 0.3380989483100846, 0.22539929887338972, 0.2028567358806922, 0.2028567358806922, 0.6085702076420766, 0.4383250238348317, 0.2922166825565545, 0.14610834127827724, 0.14610834127827724, 0.23682750555867826, 0.23682750555867826, 0.23682750555867826, 0.23682750555867826, 0.2160966074365288, 0.2160966074365288, 0.2160966074365288, 0.4321932148730576, 0.24161429282575944, 0.24161429282575944, 0.24161429282575944, 0.24161429282575944, 0.2901497173015791, 0.2901497173015791, 0.2901497173015791, 0.2901497173015791, 0.241361301187517, 0.241361301187517, 0.241361301187517, 0.241361301187517, 0.23224698300907204, 0.23224698300907204, 0.4644939660181441, 0.24379611390014444, 0.24379611390014444, 0.4875922278002889, 0.5605696207718637, 0.1868565402572879, 0.1868565402572879, 0.1868565402572879, 0.44466086638735974, 0.22233043319367987, 0.22233043319367987, 0.26250911192324317, 0.3937636678848647, 0.26250911192324317, 0.13125455596162158, 0.16609680647199723, 0.16609680647199723, 0.16609680647199723, 0.33219361294399447, 0.24905039656870687, 0.24905039656870687, 0.24905039656870687, 0.24905039656870687, 0.16128859377993615, 0.16128859377993615, 0.16128859377993615, 0.6451543751197446, 0.23120439362937575, 0.4624087872587515, 0.23120439362937575, 0.5538353459829087, 0.1846117819943029, 0.1846117819943029, 0.23940981591533805, 0.23940981591533805, 0.23940981591533805, 0.23940981591533805, 0.21430239244514387, 0.42860478489028775, 0.21430239244514387, 0.20228571332107984, 0.6068571399632395, 0.20228571332107984, 0.2942349962955786, 0.2942349962955786, 0.2942349962955786, 0.2942349962955786, 0.2937967305171261, 0.2937967305171261, 0.2937967305171261, 0.2937967305171261, 0.33765482922664714, 0.16882741461332357, 0.33765482922664714, 0.16882741461332357, 0.17917126689456683, 0.17917126689456683, 0.17917126689456683, 0.35834253378913367, 0.23224130187959652, 0.23224130187959652, 0.46448260375919304, 0.1901836645468823, 0.1901836645468823, 0.5705509936406469, 0.4472284435787027, 0.22361422178935134, 0.22361422178935134, 0.23047970380335608, 0.46095940760671217, 0.23047970380335608, 0.29029967506882076, 0.29029967506882076, 0.29029967506882076, 0.29029967506882076, 0.2892181548042353, 0.2892181548042353, 0.2892181548042353, 0.2892181548042353, 0.27491284587224496, 0.27491284587224496, 0.27491284587224496, 0.27491284587224496, 0.5229078310533811, 0.17430261035112704, 0.17430261035112704, 0.20853721038744008, 0.20853721038744008, 0.6256116311623202, 0.16342562160222174, 0.3268512432044435, 0.3268512432044435, 0.16342562160222174, 0.2360318123162795, 0.2360318123162795, 0.472063624632559, 0.2273280595141672, 0.2273280595141672, 0.4546561190283344, 0.20272879661545296, 0.20272879661545296, 0.6081863898463589, 0.23898126623859176, 0.4779625324771835, 0.23898126623859176, 0.2746587804231106, 0.2746587804231106, 0.2746587804231106, 0.2746587804231106, 0.5884308019895662, 0.19614360066318873, 0.19614360066318873, 0.2636206657159155, 0.2636206657159155, 0.2636206657159155, 0.2636206657159155, 0.20140791640418076, 0.20140791640418076, 0.20140791640418076, 0.20140791640418076, 0.20140791640418076, 0.4568025103193173, 0.22840125515965864, 0.22840125515965864, 0.5981107607801975, 0.1993702535933992, 0.1993702535933992, 0.18051507979325615, 0.3610301595865123, 0.3610301595865123, 0.18051507979325615, 0.25150419073732216, 0.25150419073732216, 0.25150419073732216, 0.25150419073732216, 0.2767550235213138, 0.2767550235213138, 0.2767550235213138, 0.2767550235213138, 0.1716812237239211, 0.1716812237239211, 0.3433624474478422, 0.1716812237239211, 0.1716812237239211, 0.23759891366086716, 0.4751978273217343, 0.23759891366086716, 0.2081283591837582, 0.2081283591837582, 0.4162567183675164, 0.2081283591837582, 0.530664514068702, 0.17688817135623397, 0.17688817135623397, 0.17688817135623397, 0.18096440865477503, 0.5428932259643251, 0.18096440865477503, 0.18096440865477503, 0.2388127326035111, 0.2388127326035111, 0.4776254652070222, 0.2994918449996829, 0.2994918449996829, 0.2994918449996829, 0.2994918449996829, 0.14731975518077403, 0.4419592655423221, 0.29463951036154806, 0.14731975518077403, 0.5272638494792871, 0.17575461649309568, 0.17575461649309568, 0.17575461649309568, 0.4303802706579364, 0.2151901353289682, 0.2151901353289682, 0.6167627047848677, 0.20558756826162258, 0.20558756826162258, 0.22938778715989946, 0.45877557431979893, 0.22938778715989946, 0.2894168272855878, 0.2894168272855878, 0.2894168272855878, 0.2894168272855878, 0.27114364516605544, 0.27114364516605544, 0.27114364516605544, 0.27114364516605544, 0.28941568867328016, 0.28941568867328016, 0.28941568867328016, 0.28941568867328016, 0.24206169809219855, 0.24206169809219855, 0.4841233961843971, 0.5642736029965644, 0.1880912009988548, 0.1880912009988548, 0.22821072038725174, 0.4564214407745035, 0.22821072038725174, 0.1322691968999417, 0.2645383937998834, 0.1322691968999417, 0.2645383937998834, 0.1322691968999417, 0.16795442668928193, 0.5038632800678458, 0.16795442668928193, 0.2602526564274372, 0.2602526564274372, 0.2602526564274372, 0.2602526564274372, 0.25974463163775185, 0.25974463163775185, 0.25974463163775185, 0.12987231581887593, 0.12987231581887593, 0.5704787594169495, 0.1901595864723165, 0.1901595864723165, 0.3160769009429767, 0.47411535141446504, 0.15803845047148835, 0.15803845047148835, 0.3116522827205921, 0.15582614136029604, 0.3116522827205921, 0.15582614136029604, 0.18066353246962508, 0.18066353246962508, 0.5419905974088752, 0.5027339820759971, 0.16757799402533238, 0.16757799402533238, 0.16757799402533238, 0.2720281615193615, 0.13601408075968074, 0.4080422422790422, 0.13601408075968074, 0.22452359979150888, 0.44904719958301775, 0.22452359979150888, 0.26329491500127483, 0.26329491500127483, 0.26329491500127483, 0.26329491500127483, 0.174919802273528, 0.349839604547056, 0.174919802273528, 0.174919802273528, 0.23595991389973503, 0.23595991389973503, 0.23595991389973503, 0.23595991389973503, 0.27411696782737877, 0.27411696782737877, 0.27411696782737877, 0.27411696782737877, 0.5765682305610077, 0.14414205764025192, 0.14414205764025192, 0.14414205764025192, 0.444178555883491, 0.2220892779417455, 0.2220892779417455, 0.34359012072163087, 0.17179506036081543, 0.17179506036081543, 0.17179506036081543, 0.23155643596841957, 0.23155643596841957, 0.23155643596841957, 0.23155643596841957, 0.23603131730845756, 0.23603131730845756, 0.4720626346169151, 0.22474120225433014, 0.4494824045086603, 0.22474120225433014, 0.16930902080074656, 0.16930902080074656, 0.5079270624022397, 0.16930902080074656, 0.21831037273633974, 0.21831037273633974, 0.21831037273633974, 0.4366207454726795, 0.24700011097395752, 0.24700011097395752, 0.24700011097395752, 0.49400022194791504, 0.21328736463211262, 0.21328736463211262, 0.21328736463211262, 0.21328736463211262, 0.22024242306616534, 0.4404848461323307, 0.22024242306616534, 0.22024242306616534, 0.4465265834557758, 0.1488421944852586, 0.2976843889705172, 0.1488421944852586, 0.2440493076408089, 0.2440493076408089, 0.2440493076408089, 0.4880986152816178, 0.29379394461020786, 0.29379394461020786, 0.29379394461020786, 0.29379394461020786, 0.5681007614473688, 0.18936692048245624, 0.18936692048245624, 0.22246976069602423, 0.44493952139204845, 0.22246976069602423, 0.28921955186839976, 0.28921955186839976, 0.28921955186839976, 0.28921955186839976, 0.2435184390149037, 0.2435184390149037, 0.2435184390149037, 0.2435184390149037, 0.5505065351537441, 0.18350217838458138, 0.18350217838458138, 0.18350217838458138, 0.2600745654349477, 0.2600745654349477, 0.2600745654349477, 0.2600745654349477, 0.19496144473295238, 0.19496144473295238, 0.5848843341988571, 0.23877500735728824, 0.23877500735728824, 0.4775500147145765, 0.21964734274353462, 0.43929468548706924, 0.21964734274353462, 0.2230372194864837, 0.4460744389729674, 0.2230372194864837, 0.19657470564889415, 0.19657470564889415, 0.5897241169466825, 0.18460027757046252, 0.18460027757046252, 0.36920055514092504, 0.18460027757046252, 0.2524368676444736, 0.2524368676444736, 0.2524368676444736, 0.2524368676444736, 0.2633593830271107, 0.2633593830271107, 0.2633593830271107, 0.2633593830271107, 0.23878242617378181, 0.23878242617378181, 0.47756485234756363, 0.20002825734007293, 0.6000847720202188, 0.20002825734007293, 0.5571477482345742, 0.18571591607819143, 0.18571591607819143, 0.2664146197612315, 0.2664146197612315, 0.2664146197612315, 0.2664146197612315, 0.22030538788807272, 0.44061077577614544, 0.22030538788807272, 0.21943315786421147, 0.43886631572842294, 0.21943315786421147, 0.2296087878266279, 0.2296087878266279, 0.2296087878266279, 0.4592175756532558, 0.28332305616669845, 0.28332305616669845, 0.28332305616669845, 0.28332305616669845, 0.21774025430156754, 0.21774025430156754, 0.4354805086031351, 0.32718781085292786, 0.16359390542646393, 0.4907817162793918, 0.24195968369381426, 0.24195968369381426, 0.48391936738762853, 0.21730550307982485, 0.4346110061596497, 0.21730550307982485, 0.21730550307982485, 0.26131520115938617, 0.26131520115938617, 0.26131520115938617, 0.26131520115938617, 0.20334119128343264, 0.20334119128343264, 0.20334119128343264, 0.20334119128343264, 0.20334119128343264, 0.21335136999355517, 0.42670273998711034, 0.21335136999355517, 0.3381012622169934, 0.50715189332549, 0.1690506311084967, 0.4559432578001563, 0.22797162890007816, 0.22797162890007816], \"Term\": [\"000\", \"000\", \"000\", \"000\", \"25-year-old\", \"25-year-old\", \"25-year-old\", \"25-year-old\", \"6-4\", \"6-4\", \"6-4\", \"6-4\", \"ambition\", \"ambition\", \"ambition\", \"ambition\", \"amnesty\", \"amnesty\", \"amnesty\", \"amnesty\", \"ankle\", \"ankle\", \"ankle\", \"argonaut\", \"argonaut\", \"argonaut\", \"artist\", \"artist\", \"artist\", \"artist\", \"atp\", \"atp\", \"atp\", \"audience\", \"audience\", \"audience\", \"audio\", \"audio\", \"audio\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"autumn\", \"autumn\", \"autumn\", \"autumn\", \"aviator\", \"aviator\", \"aviator\", \"aviator\", \"award\", \"award\", \"award\", \"award\", \"aynsley-green\", \"aynsley-green\", \"aynsley-green\", \"ball\", \"ball\", \"ball\", \"bates\", \"bates\", \"bates\", \"bbc\", \"bbc\", \"bbc\", \"bbc\", \"bench\", \"bench\", \"bench\", \"bench\", \"benin\", \"benin\", \"benin\", \"blog\", \"blog\", \"blog\", \"blue\", \"blue\", \"blue\", \"blue\", \"bonus\", \"bonus\", \"bonus\", \"bowles\", \"bowles\", \"bowles\", \"break\", \"break\", \"break\", \"break\", \"break\", \"broadband\", \"broadband\", \"broadband\", \"broadband\", \"browser\", \"browser\", \"browser\", \"bus\", \"bus\", \"bus\", \"bus\", \"captain\", \"captain\", \"captain\", \"captain\", \"carpenter\", \"carpenter\", \"carpenter\", \"celebrity\", \"celebrity\", \"celebrity\", \"cell\", \"cell\", \"cell\", \"cell\", \"child\", \"child\", \"child\", \"child\", \"club\", \"club\", \"club\", \"club\", \"club\", \"coach\", \"coach\", \"coach\", \"coach\", \"code\", \"code\", \"code\", \"code\", \"cole\", \"cole\", \"cole\", \"company\", \"company\", \"company\", \"company\", \"connors\", \"connors\", \"connors\", \"conservative\", \"conservative\", \"conservative\", \"conservative\", \"console\", \"console\", \"console\", \"corp\", \"corp\", \"corp\", \"corp\", \"crude\", \"crude\", \"crude\", \"cup\", \"cup\", \"cup\", \"cup\", \"dam\", \"dam\", \"dam\", \"davis\", \"davis\", \"davis\", \"dent\", \"dent\", \"dent\", \"dicaprio\", \"dicaprio\", \"dicaprio\", \"dicaprio\", \"donation\", \"donation\", \"donation\", \"donation\", \"drug\", \"drug\", \"drug\", \"e-mail\", \"e-mail\", \"e-mail\", \"ebbers\", \"ebbers\", \"ebbers\", \"economy\", \"economy\", \"economy\", \"economy\", \"england\", \"england\", \"england\", \"england\", \"england\", \"face\", \"face\", \"face\", \"face\", \"farrell\", \"farrell\", \"farrell\", \"farrell\", \"fbi\", \"fbi\", \"fbi\", \"federer\", \"federer\", \"federer\", \"ferguson\", \"ferguson\", \"ferguson\", \"ferguson\", \"fiat\", \"fiat\", \"fiat\", \"fiat\", \"film\", \"film\", \"film\", \"film\", \"firefox\", \"firefox\", \"firefox\", \"firm\", \"firm\", \"firm\", \"firm\", \"fourth\", \"fourth\", \"fourth\", \"fourth\", \"fox\", \"fox\", \"fox\", \"fox\", \"front\", \"front\", \"front\", \"front\", \"gamble\", \"gamble\", \"gamble\", \"gamble\", \"german\", \"german\", \"german\", \"german\", \"gibbon\", \"gibbon\", \"gibbon\", \"goldsmith\", \"goldsmith\", \"goldsmith\", \"good\", \"good\", \"good\", \"good\", \"gorge\", \"gorge\", \"gorge\", \"government\", \"government\", \"government\", \"government\", \"growth\", \"growth\", \"growth\", \"growth\", \"guilty\", \"guilty\", \"guilty\", \"guilty\", \"hague\", \"hague\", \"hague\", \"hague\", \"halloween\", \"halloween\", \"halloween\", \"hendrix\", \"hendrix\", \"hendrix\", \"henman\", \"henman\", \"henman\", \"henman\", \"hill\", \"hill\", \"hill\", \"hingis\", \"hingis\", \"hingis\", \"hip-hop\", \"hip-hop\", \"hip-hop\", \"hip-hop\", \"hopman\", \"hopman\", \"hopman\", \"hopman\", \"howard\", \"howard\", \"howard\", \"howard\", \"human\", \"human\", \"human\", \"human\", \"hutt\", \"hutt\", \"hutt\", \"ice\", \"ice\", \"ice\", \"immunisation\", \"immunisation\", \"immunisation\", \"indonesia\", \"indonesia\", \"indonesia\", \"insulation\", \"insulation\", \"insulation\", \"insulation\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"intention\", \"intention\", \"intention\", \"intention\", \"ireland\", \"ireland\", \"ireland\", \"jamieson\", \"jamieson\", \"jamieson\", \"japan\", \"japan\", \"japan\", \"japan\", \"johansson\", \"johansson\", \"johansson\", \"journalist\", \"journalist\", \"journalist\", \"kasabian\", \"kasabian\", \"kasabian\", \"kerekou\", \"kerekou\", \"kerekou\", \"khan\", \"khan\", \"khan\", \"khan\", \"khodorkovsky\", \"khodorkovsky\", \"khodorkovsky\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"league\", \"league\", \"league\", \"league\", \"league\", \"lebedev\", \"lebedev\", \"lebedev\", \"lewsey\", \"lewsey\", \"lewsey\", \"lord\", \"lord\", \"lord\", \"lord\", \"marketing\", \"marketing\", \"marketing\", \"marketing\", \"marsh\", \"marsh\", \"marsh\", \"marsh\", \"match\", \"match\", \"match\", \"match\", \"match\", \"merck\", \"merck\", \"merck\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"million\", \"million\", \"million\", \"million\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"msn\", \"msn\", \"msn\", \"mtv\", \"mtv\", \"mtv\", \"mtv\", \"music\", \"music\", \"music\", \"music\", \"network\", \"network\", \"network\", \"network\", \"nintendo\", \"nintendo\", \"nintendo\", \"ntpc\", \"ntpc\", \"ntpc\", \"ocean\", \"ocean\", \"ocean\", \"osbourne\", \"osbourne\", \"osbourne\", \"osbourne\", \"osbournes\", \"osbournes\", \"osbournes\", \"osbournes\", \"ozzy\", \"ozzy\", \"ozzy\", \"ozzy\", \"page\", \"page\", \"page\", \"panda\", \"panda\", \"panda\", \"parker\", \"parker\", \"parker\", \"party\", \"party\", \"party\", \"party\", \"party\", \"pension\", \"pension\", \"pension\", \"pensioner\", \"pensioner\", \"pensioner\", \"pensioner\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pernod\", \"pernod\", \"pernod\", \"phone\", \"phone\", \"phone\", \"phone\", \"player\", \"player\", \"player\", \"player\", \"pop\", \"pop\", \"pop\", \"power\", \"power\", \"power\", \"power\", \"price\", \"price\", \"price\", \"price\", \"prince\", \"prince\", \"prince\", \"pupil\", \"pupil\", \"pupil\", \"pupil\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"ranger\", \"ranger\", \"ranger\", \"ranger\", \"ranieri\", \"ranieri\", \"ranieri\", \"ranieri\", \"rate\", \"rate\", \"rate\", \"rate\", \"referee\", \"referee\", \"referee\", \"right\", \"right\", \"right\", \"right\", \"robinson\", \"robinson\", \"robinson\", \"robinson\", \"rochus\", \"rochus\", \"rochus\", \"roddick\", \"roddick\", \"roddick\", \"rugby\", \"rugby\", \"rugby\", \"rugby\", \"sayeed\", \"sayeed\", \"sayeed\", \"sayeed\", \"scholl\", \"scholl\", \"scholl\", \"scholl\", \"school\", \"school\", \"school\", \"school\", \"sequel\", \"sequel\", \"sequel\", \"sequel\", \"share\", \"share\", \"share\", \"share\", \"singapore\", \"singapore\", \"singapore\", \"singapore\", \"slovakia\", \"slovakia\", \"slovakia\", \"slovakia\", \"solskjaer\", \"solskjaer\", \"solskjaer\", \"sound\", \"sound\", \"sound\", \"spitzer\", \"spitzer\", \"spitzer\", \"spitzer\", \"stand\", \"stand\", \"stand\", \"stand\", \"stock\", \"stock\", \"stock\", \"stock\", \"straw\", \"straw\", \"straw\", \"straw\", \"student\", \"student\", \"student\", \"submission\", \"submission\", \"submission\", \"sumitomo\", \"sumitomo\", \"sumitomo\", \"titan\", \"titan\", \"titan\", \"tobacco\", \"tobacco\", \"tobacco\", \"top\", \"top\", \"top\", \"top\", \"tps\", \"tps\", \"tps\", \"tps\", \"truant\", \"truant\", \"truant\", \"truant\", \"tuc\", \"tuc\", \"tuc\", \"ufj\", \"ufj\", \"ufj\", \"ukraine\", \"ukraine\", \"ukraine\", \"valencia\", \"valencia\", \"valencia\", \"valencia\", \"villa\", \"villa\", \"villa\", \"vioxx\", \"vioxx\", \"vioxx\", \"virgin\", \"virgin\", \"virgin\", \"virgin\", \"voting\", \"voting\", \"voting\", \"voting\", \"waiting\", \"waiting\", \"waiting\", \"wale\", \"wale\", \"wale\", \"web\", \"web\", \"web\", \"west\", \"west\", \"west\", \"west\", \"wilkinson\", \"wilkinson\", \"wilkinson\", \"wilkinson\", \"winter\", \"winter\", \"winter\", \"winter\", \"winter\", \"worldcom\", \"worldcom\", \"worldcom\", \"yukos\", \"yukos\", \"yukos\", \"yushchenko\", \"yushchenko\", \"yushchenko\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2, 5, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el990828773112255206394267984\", ldavis_el990828773112255206394267984_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el990828773112255206394267984\", ldavis_el990828773112255206394267984_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el990828773112255206394267984\", ldavis_el990828773112255206394267984_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.008919  0.000455       1        1  26.996248\n",
       "2     -0.003884  0.004725       2        1  24.485375\n",
       "1     -0.002370 -0.007193       3        1  24.403808\n",
       "4     -0.001465  0.001290       4        1  14.779817\n",
       "3     -0.001200  0.000723       5        1   9.334751, topic_info=          Term      Freq     Total Category  logprob  loglift\n",
       "1358     hague  6.000000  6.000000  Default  30.0000  30.0000\n",
       "808      party  7.000000  7.000000  Default  29.0000  29.0000\n",
       "4303      fiat  4.000000  4.000000  Default  28.0000  28.0000\n",
       "4961       fox  4.000000  4.000000  Default  27.0000  27.0000\n",
       "2843    sayeed  4.000000  4.000000  Default  26.0000  26.0000\n",
       "...        ...       ...       ...      ...      ...      ...\n",
       "1685    winter  0.864569  4.917843   Topic5  -7.6507   0.6330\n",
       "808      party  0.985550  7.560339   Topic5  -7.5197   0.3340\n",
       "2194  donation  0.813427  5.426253   Topic5  -7.7117   0.4737\n",
       "385    captain  0.741026  3.992159   Topic5  -7.8049   0.6874\n",
       "394    england  0.810248  6.615710   Topic5  -7.7156   0.2716\n",
       "\n",
       "[226 rows x 6 columns], token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "0         1  0.164791          000\n",
       "0         2  0.329582          000\n",
       "0         3  0.329582          000\n",
       "0         4  0.164791          000\n",
       "983       1  0.296807  25-year-old\n",
       "...     ...       ...          ...\n",
       "4756      2  0.507152        yukos\n",
       "4756      3  0.169051        yukos\n",
       "3884      1  0.455943   yushchenko\n",
       "3884      2  0.227972   yushchenko\n",
       "3884      3  0.227972   yushchenko\n",
       "\n",
       "[676 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 2, 5, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interacting with LDA output\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = gensimvis.prepare(lda_model_tfidf, bow_corpus, dic_bow)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating LDA models: Topic coherence\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "goodLdaModel = LdaModel(corpus=bow_corpus, id2word=dic_bow, iterations=50, num_topics=2)\n",
    "badLdaModel = LdaModel(corpus=bow_corpus, id2word=dic_bow, iterations=1, num_topics=2)\n",
    "\n",
    "goodcm = CoherenceModel(model=goodLdaModel, corpus=bow_corpus, dictionary=dic_bow, coherence='u_mass')\n",
    "badcm  = CoherenceModel(model=badLdaModel, corpus=bow_corpus, dictionary=dic_bow, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6388275355777575"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodcm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=bow_corpus, dictionary=dic_bow, coherence='c_v')\n",
    "badcm  = CoherenceModel(model=badLdaModel, texts=bow_corpus, dictionary=dic_bow, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echemochek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "C:\\Users\\echemochek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodcm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badcm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echemochek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\models\\lsimodel.py:963: DeprecationWarning: Please use `csc_matvecs` from the `scipy.sparse` namespace, the `scipy.sparse.sparsetools` namespace is deprecated.\n",
      "  sparsetools.csc_matvecs(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.158*\"party\" + 0.143*\"hague\" + 0.089*\"government\" + 0.086*\"price\" + 0.085*\"people\" + 0.084*\"rate\" + 0.082*\"england\" + 0.080*\"film\" + 0.077*\"donation\" + 0.077*\"music\"'),\n",
       " (1,\n",
       "  '-0.588*\"hague\" + -0.272*\"party\" + -0.160*\"front\" + -0.150*\"ambition\" + -0.122*\"leadership\" + -0.115*\"politics\" + -0.113*\"william\" + -0.113*\"bench\" + -0.103*\"leader\" + -0.103*\"conservative\"'),\n",
       " (2,\n",
       "  '-0.204*\"price\" + -0.197*\"rate\" + -0.172*\"growth\" + -0.154*\"bank\" + -0.150*\"economy\" + -0.140*\"oil\" + -0.127*\"crude\" + -0.126*\"quarter\" + 0.125*\"rugby\" + -0.100*\"market\"'),\n",
       " (3,\n",
       "  '-0.256*\"hague\" + -0.150*\"price\" + -0.128*\"rate\" + 0.125*\"film\" + 0.117*\"party\" + 0.108*\"donation\" + -0.107*\"bank\" + -0.106*\"england\" + 0.104*\"people\" + 0.104*\"government\"'),\n",
       " (4,\n",
       "  '0.580*\"film\" + 0.176*\"festival\" + 0.174*\"dicaprio\" + 0.161*\"scholl\" + 0.138*\"award\" + 0.115*\"starring\" + 0.108*\"hague\" + 0.090*\"hill\" + 0.081*\"rating\" + 0.080*\"halloween\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSI\n",
    "from gensim.models import LsiModel, CoherenceModel\n",
    "\n",
    "lsi_model = LsiModel(corpus=corpus_tfidf, id2word=dic_bow, num_topics=5)\n",
    "lsi_model.print_topics(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.158*\"party\" + 0.143*\"hague\" + 0.089*\"government\" + 0.086*\"price\" + 0.085*\"people\" + 0.084*\"rate\" + 0.082*\"england\" + 0.080*\"film\" + 0.077*\"donation\" + 0.077*\"music\"'),\n",
       " (1,\n",
       "  '-0.588*\"hague\" + -0.272*\"party\" + -0.160*\"front\" + -0.150*\"ambition\" + -0.122*\"leadership\" + -0.115*\"politics\" + -0.113*\"william\" + -0.113*\"bench\" + -0.103*\"leader\" + -0.103*\"conservative\"'),\n",
       " (2,\n",
       "  '-0.204*\"price\" + -0.197*\"rate\" + -0.172*\"growth\" + -0.154*\"bank\" + -0.150*\"economy\" + -0.140*\"oil\" + -0.127*\"crude\" + -0.126*\"quarter\" + 0.125*\"rugby\" + -0.100*\"market\"'),\n",
       " (3,\n",
       "  '-0.256*\"hague\" + -0.150*\"price\" + -0.128*\"rate\" + 0.125*\"film\" + 0.117*\"party\" + 0.108*\"donation\" + -0.107*\"bank\" + -0.106*\"england\" + 0.104*\"people\" + 0.104*\"government\"'),\n",
       " (4,\n",
       "  '0.580*\"film\" + 0.176*\"festival\" + 0.174*\"dicaprio\" + 0.161*\"scholl\" + 0.138*\"award\" + 0.115*\"starring\" + 0.108*\"hague\" + 0.090*\"hill\" + 0.081*\"rating\" + 0.080*\"halloween\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model.print_topics(num_topics=5, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echemochek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\models\\lsimodel.py:963: DeprecationWarning: Please use `csc_matvecs` from the `scipy.sparse` namespace, the `scipy.sparse.sparsetools` namespace is deprecated.\n",
      "  sparsetools.csc_matvecs(\n"
     ]
    }
   ],
   "source": [
    "# Determining optimum number of topics using coherence values \n",
    "\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "min_topics, max_topics, step = 1, 10, 1\n",
    "for i in range(min_topics, max_topics, step):\n",
    "    model = LsiModel(corpus_tfidf, id2word=dic_bow, num_topics=i)\n",
    "    model_list.append(model)\n",
    "    coherencemodel = CoherenceModel(model=model, texts=df.cleanText, \\\n",
    "        dictionary=dic_bow, coherence='c_v')\n",
    "    coherence_values.append(coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = range(min_topics, max_topics, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.legend((\"coherence_values\"), loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Keywords to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfe9ce709e982859ebd8c1b094ee35d9f73a27801040ad55cc46450c9d5cadda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
